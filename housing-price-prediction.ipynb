{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport seaborn as sns\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')\ntest_data_copy = pd.read_csv('../input/test.csv')\nn_rows_train = train_data.shape[0]\nY_train = train_data.iloc[:,-1]\n#train_data = train_data.iloc[:,:-1]\n\ntotal_data = train_data.append(test_data, sort=False)\ntotal_data = total_data.drop(['Id','SalePrice'],axis=1)\ntotal_data.head()\nprint(test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"155e54433e1de316114739f283745217e7a66961"},"cell_type":"code","source":"#correlation matrix\ncorrmat = train_data.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b52654d330a9a39df76ccfd87ce418a1ce8f5a4"},"cell_type":"code","source":"# NOTE: we can draw scatter plots, it is  just for visualization of relation between different variables\nsns.set()\ncols = ['SalePrice','OverallQual', 'GrLivArea','TotalBsmtSF', 'FullBath','YearBuilt']\nsns.pairplot(train_data[cols], height=2.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4e7e92c183a08d83e114e1f94d2f2a96e821b9b"},"cell_type":"code","source":"#Missing data treatment\ntrain_data = train_data.iloc[:,:-1]\ntotal_missing_values = total_data.isnull().sum().sort_values(ascending=False)\npercentage_missing_data = (100*(total_data.isnull().sum()/total_data.isnull().count())).sort_values(ascending=False)\nmissing_data = pd.concat([total_missing_values, percentage_missing_data], axis=1, keys=['total_missing_values','percentage_missing_data'])\nmissing_data.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0909c55d8bf8a0d5dbe1f5fa529aad7ff0dd34c4"},"cell_type":"code","source":"#missing value treatment\n#we can see some of the features which have high missing values are categorical, \n#so we will replce their missing value by \"None\" which represents NA category as given in variable description\ntotal_data[\"PoolQC\"] = total_data[\"PoolQC\"].fillna(\"None\") \ntotal_data[\"MiscFeature\"] = total_data[\"MiscFeature\"].fillna(\"None\") \ntotal_data[\"Alley\"] = total_data[\"Alley\"].fillna(\"None\") \ntotal_data[\"Fence\"] = total_data[\"Fence\"].fillna(\"None\")\ntotal_data[\"FireplaceQu\"] = total_data[\"FireplaceQu\"].fillna(\"None\") \n\n# LotFrontage is a continuous variable, so we replace missing values from houses of same neighborhood\n# and take their median\ntotal_data[\"LotFrontage\"] = total_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))\n\ntotal_data[\"GarageCond\"] = total_data[\"GarageCond\"].fillna(\"None\") \ntotal_data[\"GarageQual\"] = total_data[\"GarageQual\"].fillna(\"None\") \ntotal_data[\"GarageFinish\"] = total_data[\"GarageFinish\"].fillna(\"None\") \ntotal_data[\"GarageType\"] = total_data[\"GarageType\"].fillna(\"None\")\n\n# we have replaced garage variables by none i.e. they don't have garage, so we can replace numeric\n# variables of garage =0 \ntotal_data[\"GarageYrBlt\"] = total_data[\"GarageYrBlt\"].fillna(0)\ntotal_data[\"GarageCars\"] = total_data[\"GarageCars\"].fillna(0)\ntotal_data[\"GarageArea\"] = total_data[\"GarageArea\"].fillna(0)\n\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    total_data[col] = total_data[col].fillna(0)\n    \nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    total_data[col] = total_data[col].fillna('None')\n    \ntotal_data[\"MasVnrType\"] = total_data[\"MasVnrType\"].fillna(\"None\")\ntotal_data[\"MasVnrArea\"] = total_data[\"MasVnrArea\"].fillna(0)\n\n# MSZoning is categorical variable but doesn't have any NA category, so we replace missing values \n# by most occured value in that variable\ntotal_data['MSZoning'] = total_data['MSZoning'].fillna(total_data['MSZoning'].mode()[0])\ntotal_data['MSZoning'] = total_data['MSZoning'].fillna(total_data['MSZoning'].mode()[0])\n# NOTE: there are other variables which have 1or 2 missing values, they are very los, we can even drop \n# those obervations\n# this variable has same value for all observations except 3, so we drop it\ntotal_data = total_data.drop(['Utilities'], axis=1)\n\ntotal_data[\"Functional\"] = total_data[\"Functional\"].fillna(\"Typ\")\nfor col in ('KitchenQual', 'Exterior1st', 'Exterior2nd', 'SaleType'):\n    total_data[col] = total_data[col].fillna(total_data[col].mode()[0])\ntotal_data['MSSubClass'] = total_data['MSSubClass'].fillna(\"None\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"447d2c57c4668e131dc28fda1063783cbe3e4f1d"},"cell_type":"code","source":"total_data['Electrical'] = total_data['Electrical'].fillna(total_data['Electrical'].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8d7a2cc9ce741322d0a6f7ad419c37df698986d"},"cell_type":"code","source":"# converting some numericla variiables that really are categories\ntotal_data['MSSubClass'] = total_data['MSSubClass'].apply(str)\n\n\n#Changing OverallCond into a categorical variable\ntotal_data['OverallCond'] = total_data['OverallCond'].astype(str)\n\n\n#Year and month sold are transformed into categorical features.\ntotal_data['YrSold'] = total_data['YrSold'].astype(str)\ntotal_data['MoSold'] = total_data['MoSold'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"364e2a30d376c6c7ca028d52455025cd46bdd061"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ncol = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n\nfor c in col:\n    lb = LabelEncoder()\n    lb.fit(total_data[c])\n    total_data[c] = lb.transform(total_data[c])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46c4559d8989c3f59e791b5c51e7e7029ee77095"},"cell_type":"code","source":"print('Shape all_data: {}'.format(total_data.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a595af449de095343af7aa61024f29f1e6c0eda7"},"cell_type":"code","source":"from scipy.stats import skew\n#reducing skewness of all features and target variable\nY_train1 = np.log1p(Y_train)\n\nn_rows_train = train_data.shape[0];\ntrain_data = total_data.iloc[:n_rows_train,:]\ntest_data = total_data.iloc[n_rows_train:,:]\n#finding numerical features\n\nfeatures = total_data.dtypes[total_data.dtypes != \"object\"].index\n\n#finding skewness of all variables\nskewed_feats = total_data[features].apply(lambda x: skew(x.dropna()))\n#adjusting features having skewness >0.75\nskewed_feats = skewed_feats[skewed_feats > 0.75]\nskewed_feats = skewed_feats.index\ntotal_data[skewed_feats] = np.log1p(total_data[skewed_feats])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcbc58be627aa1f5e69b8bd0993cac735299b545"},"cell_type":"code","source":"# although we have applied norm distribution to all numeric variables, but here we will plot graph of\n# target variable only\n# NOTE: y axisis probability density estimates, # to get freq, use kde= False\nchart1, ax1 = plt.subplots()\nsns.distplot(Y_train, norm_hist=False,ax=ax1);\n#after applying logarithm, we get plot relatively simiar to norm distribution\nchart2, ax2 = plt.subplots()\nsns.distplot(Y_train1, norm_hist=False,ax=ax2);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b272284af89a1433d1c5bd69b30e11b5d21c0b3"},"cell_type":"code","source":"# now converting categorical features to one hot encoding vectors\ntotal_data_oh = pd.get_dummies(total_data)\ntotal_data_oh.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1b28eca8f52a3713d9330aac42cfb15ceec40db"},"cell_type":"code","source":"#split between X and test data\nX = total_data_oh.iloc[:n_rows_train,:]\ntest_data = total_data_oh.iloc[n_rows_train:,:]\nprint(X.shape)\n\n#  split X between training and testing set\nx_train, x_test, y_train, y_test = train_test_split(X,Y_train1, test_size=0.3, shuffle=True) \n'''\n#PCA\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=5)\npca = pca.fit(x_train)\nprincipalComponents_xtrain = pca.transform(x_train)\nprincipalComponents_xtest = pca.transform(x_test)\nx_train = pd.DataFrame(principalComponents_xtrain)\nx_test = pd.DataFrame(principalComponents_xtest)\n'''\n# I have tried PCA code above, but the model is performing bad with it. So, I am not applying PCA.\n#scaling the data\nscaler = RobustScaler()\nscaler = scaler.fit(x_train)\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)\ntest_data = scaler.transform(test_data)\nx_train = pd.DataFrame(x_train)\nx_test = pd.DataFrame(x_test)\ntest_data = pd.DataFrame(test_data)\nx_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a4f2ccc8949b5ab7f7ae96c0326472355691816"},"cell_type":"code","source":"print(Y_train1.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9fb84152aaa3b207023861fbab6f2353dfa07e87"},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\n'''\nCross-validation is a resampling procedure used to evaluate machine learning models on a limited \ndata sample. It is just used to check how this particular model will perform on different test sets. \nIt is not used to say whether this particuclar model is best or not.\nAt the end final predictions are made by model.fit and model.predict only.\n'''\n#Validation function\nn_folds = 5\n\ndef rmse_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(x_train.values)\n    rmse= np.sqrt(-cross_val_score(model, X, Y_train1, scoring=\"neg_mean_squared_error\", cv = kf)) \n    # this computes rmse of each fold\n    return(rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d709c0eaf322afba216022d6011119e2a625d80"},"cell_type":"code","source":"#modelling\nfrom sklearn.neural_network import MLPRegressor\nmlp = MLPRegressor(hidden_layer_sizes=(10,6,5,3),activation='relu',alpha = 0.0001,max_iter = 1000,solver='lbfgs')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efc22353b69ad3c70cf8038a76d0dd473ae7b815"},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\ndef rmse(y_pred, y_test):\n    rmse = sqrt(mean_squared_error(y_test,y_pred))\n    return rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13ea99cf8aca6bdfbc99e1e801c512232acd1bb9"},"cell_type":"code","source":"from sklearn.linear_model import Lasso\nlasso = Lasso(alpha=0.0005)\nlasso.fit(x_train, y_train)\n#pred = lasso.predict(x_test)\n#print(rmse(pred,y_test))\n#print(rmse(lasso, x_train, y_train, x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"128620ed38e2d6885ce419ec5ec6be0a95a32361"},"cell_type":"code","source":"import xgboost as xgb\nxgb_model = xgb.XGBRegressor()\nxgb_model.fit(x_train, y_train)\n#print(rmse(xgb_model, x_train, y_train, x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f01d9ac3ccc6439cb7f803564f408bb654c5e94a"},"cell_type":"code","source":"from sklearn.linear_model import ElasticNet\nelastic_net_model = ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3)\nelastic_net_model.fit(x_train, y_train)\n#print(rmse(elastic_net_model, x_train, y_train, x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6aa11aff1a2530f507fee7e80f0b540fb69b1f88"},"cell_type":"code","source":"#making predictions on test set\ny_pred_elastic_net_test_data = np.expm1(elastic_net_model.predict(test_data))\ny_pred_lasso_test_data = np.expm1(lasso.predict(test_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"acb6cb9b8d2ffbe74c8d3c9a2b22387d6f9d74d3"},"cell_type":"code","source":"pred = 0.3*y_pred_elastic_net_test_data + 0.7*y_pred_lasso_test_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec0b848fc8f4e76d7409d152ac74b56ceac34306"},"cell_type":"code","source":"solution = pd.DataFrame({\"id\":test_data_copy.Id, \"SalePrice\":pred})\nsolution.to_csv(\"housing_pricefinal.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3de81209c42c548477be541f729262398116ae47"},"cell_type":"code","source":"#y_pred_lasso_test_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfa35616b191c3fd94398844eebd46d7d496e453"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}